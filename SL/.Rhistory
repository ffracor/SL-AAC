IC_up_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.975)
IC_down_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.025)
medie_pre[k] = mean(res_predizioni[["t"]][,k])
isDentro[k] <- ifelse(y_test[k] >= IC_down_predictions[k] && y_test[k] <= IC_up_predictions[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred <- data.frame(medie_pre,  IC_down_predictions, y_test, IC_up_predictions,isDentro)
sum(isDentro)
sum(isDentro)
IC_up_predictions <- numeric(nrow(x[-train,]))
IC_down_predictions <- numeric(nrow(x[-train,]))
medie_pre <- numeric(length(IC_up_predictions))
y_test <- x[-train,4]
isDentro <- numeric(ncol(res_predizioni[["t"]]))
for (k in 1:ncol(res_predizioni[["t"]])){
IC_up_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.995)
IC_down_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.005)
medie_pre[k] = mean(res_predizioni[["t"]][,k])
isDentro[k] <- ifelse(y_test[k] >= IC_down_predictions[k] && y_test[k] <= IC_up_predictions[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred <- data.frame(medie_pre,  IC_down_predictions, y_test, IC_up_predictions,isDentro)
sum(isDentro)
IC_up_predictions <- numeric(nrow(x[-train,]))
IC_down_predictions <- numeric(nrow(x[-train,]))
medie_pre <- numeric(length(IC_up_predictions))
y_test <- x[-train,4]
isDentro <- numeric(ncol(res_predizioni[["t"]]))
for (k in 1:ncol(res_predizioni[["t"]])){
IC_up_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.975)
IC_down_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.025)
medie_pre[k] = mean(res_predizioni[["t"]][,k])
isDentro[k] <- ifelse(y_test[k] >= IC_down_predictions[k] && y_test[k] <= IC_up_predictions[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred <- data.frame(medie_pre,  IC_down_predictions, y_test, IC_up_predictions,isDentro)
sum(isDentro)
sqrt(0.024)
sqrt(0.0024)
View(tabella_pred)
IC_up_predictions <- numeric(nrow(x[-train,]))
IC_down_predictions <- numeric(nrow(x[-train,]))
medie_pre <- numeric(length(IC_up_predictions))
y_test <- x[-train,4]
isDentro <- numeric(ncol(res_predizioni[["t"]]))
for (k in 1:ncol(res_predizioni[["t"]])){
IC_up_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.975)
IC_down_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.025)
medie_pre[k] = mean(res_predizioni[["t"]][,k])
isDentro[k] <- ifelse(y_test[k] >= IC_down_predictions[k] && y_test[k] <= IC_up_predictions[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred <- data.frame(medie_pre,  IC_down_predictions, y_test, IC_up_predictions,isDentro)
View(tabella_pred)
View(tabella_pred)
ercentile(0.95)
pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
qnorm(0.975, mean= 0, std  = 1)
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
qnorm(0.975, mean= 0, std=1)
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
qnorm(0.975, mean=0, sd=1)
res_predizioni[["t"]]
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
z = qnorm(0.975, mean=0, sd=1)
for (k in 1:length(rand_fit)){
IC_up_predictions_2[k] <- rand_fit[k] + z*sqrt(MSE_rand)
IC_down_predictions_2[k] <- rand_fit[k] - z*sqrt(MSE_rand)
isDentro_2[k] <- ifelse(y_test[k] >= IC_down_predictions_2[k] && y_test[k] <= IC_up_predictions_2[k], 1, 0)
}
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
z = qnorm(0.975, mean=0, sd=1)
IC_up_predictions_2 <- numeric(nrow(x[-train,]))
IC_down_predictions_2 <- numeric(nrow(x[-train,]))
isDentro_2 <- numeric(length(rand_fit))
for (k in 1:length(rand_fit)){
IC_up_predictions_2[k] <- rand_fit[k] + z*sqrt(MSE_rand)
IC_down_predictions_2[k] <- rand_fit[k] - z*sqrt(MSE_rand)
isDentro_2[k] <- ifelse(y_test[k] >= IC_down_predictions_2[k] && y_test[k] <= IC_up_predictions_2[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred <- data.frame(medie_pre,  IC_down_predictions, y_test, IC_up_predictions,isDentro)
#media del valore IC up IC down
tabella_pred_2 <- data.frame(rand_fit,  IC_down_predictions_2, y_test, IC_up_predictions_2,isDentro_2)
sum(isDentro_2)
37/40
27/39
37/39
hist(rand_fit - y_test)
View(tabella_pred_2)
View(tabella_pred_2)
IC_up_predictions_2 <- numeric(nrow(x[-train,]))
IC_down_predictions_2 <- numeric(nrow(x[-train,]))
isDentro_2 <- numeric(length(rand_fit))
for (k in 1:length(rand_fit)){
IC_up_predictions_2[k] <- rand_fit[k] + z*sqrt(var(y_test))
IC_down_predictions_2[k] <- rand_fit[k] - z*sqrt(var(y_test))
isDentro_2[k] <- ifelse(y_test[k] >= IC_down_predictions_2[k] && y_test[k] <= IC_up_predictions_2[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred <- data.frame(medie_pre,  IC_down_predictions, y_test, IC_up_predictions,isDentro)
#media del valore IC up IC down
tabella_pred_2 <- data.frame(rand_fit,  IC_down_predictions_2, y_test, IC_up_predictions_2,isDentro_2)
View(tabella_pred_2)
View(tabella_pred_2)
IC_up_predictions_2 <- numeric(nrow(x[-train,]))
IC_down_predictions_2 <- numeric(nrow(x[-train,]))
isDentro_2 <- numeric(length(rand_fit))
for (k in 1:length(rand_fit)){
IC_up_predictions_2[k] <- rand_fit[k] + z*sqrt(MSE_rand)
IC_down_predictions_2[k] <- rand_fit[k] - z*sqrt(MSE_rand)
isDentro_2[k] <- ifelse(y_test[k] >= IC_down_predictions_2[k] && y_test[k] <= IC_up_predictions_2[k], 1, 0)
}
View(tabella_pred_2)
View(tabella_pred_2)
sum(isDentro)
isDentro_2
sum(isDentro_2)
View(tabella_pred_2)
View(tabella_pred_2)
View(tabella_pred_2)
View(tabella_pred_2)
#media del valore IC up IC down
tabella_pred_2 <- data.frame(rand_fit,  IC_down_predictions_2, y_test, IC_up_predictions_2,isDentro_2)
#media del valore IC up IC down
tabella_pred_2 <- data.frame(rand_fit,  IC_down_predictions_2, y_test, IC_up_predictions_2,isDentro_2)
View(tabella_pred_2)
train <- sample(dim(x)[1],floor(dim(x)[1]*0.75),replace = FALSE);
rand_model <- randomForest(x$Sleep.efficiency ~ . ,data = x, subset = train,
mtry = floor(sqrt(ncol(x)-1)), importance = TRUE, replace = TRUE, ntree = 200)
# import libraries
library(tidyverse)
library(caret)
library(leaps)
library("MASS")
library("glmnet")
library ( ISLR2 )
library ( boot )
library(tree)
library ( randomForest )
library ( gbm )
library(recipes)
library("tseries")
library(tseries)
library(xtable)
library(groupdata2)
library(tseries)
set.seed(42)
train <- sample(dim(x)[1],floor(dim(x)[1]*0.75),replace = FALSE);
rand_model <- randomForest(x$Sleep.efficiency ~ . ,data = x, subset = train,
mtry = floor(sqrt(ncol(x)-1)), importance = TRUE, replace = TRUE, ntree = 200)
rand_fit <- predict(rand_model, newdata = x[-train,])
MSE_rand = mean((x$Sleep.efficiency[-train] - rand_fit)^2)
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
z = qnorm(0.975, mean=0, sd=1)
IC_up_predictions_2 <- numeric(nrow(x[-train,]))
IC_down_predictions_2 <- numeric(nrow(x[-train,]))
isDentro_2 <- numeric(length(rand_fit))
for (k in 1:length(rand_fit)){
IC_up_predictions_2[k] <- rand_fit[k] + z*sqrt(MSE_rand)
IC_down_predictions_2[k] <- rand_fit[k] - z*sqrt(MSE_rand)
isDentro_2[k] <- ifelse(y_test[k] >= IC_down_predictions_2[k] && y_test[k] <= IC_up_predictions_2[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred_2 <- data.frame(rand_fit,  IC_down_predictions_2, y_test, IC_up_predictions_2,isDentro_2)
y_test <- x[-train,4]
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
z = qnorm(0.975, mean=0, sd=1)
IC_up_predictions_2 <- numeric(nrow(x[-train,]))
IC_down_predictions_2 <- numeric(nrow(x[-train,]))
isDentro_2 <- numeric(length(rand_fit))
for (k in 1:length(rand_fit)){
IC_up_predictions_2[k] <- rand_fit[k] + z*sqrt(MSE_rand)
IC_down_predictions_2[k] <- rand_fit[k] - z*sqrt(MSE_rand)
isDentro_2[k] <- ifelse(y_test[k] >= IC_down_predictions_2[k] && y_test[k] <= IC_up_predictions_2[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred_2 <- data.frame(rand_fit,  IC_down_predictions_2, y_test, IC_up_predictions_2,isDentro_2)
View(tabella_pred_2)
hist(y_test - rad_fit)
hist(y_test - rand_fit)
View(tabella_pred_2)
res_predizioni_3 <- boot(x,get_alpha_tree,R=2000) #attenzione 'x' minuscola in questo caso
res_predizioni_3[["t"]]
hist(res[["t"]][,1])
IC_up_predictions_3 <- numeric(nrow(x[-train,]))
IC_down_predictions_3 <- numeric(nrow(x[-train,]))
# import libraries
library(tidyverse)
library(caret)
library(leaps)
library("MASS")
library("glmnet")
library ( ISLR2 )
library ( boot )
library(tree)
library ( randomForest )
library ( gbm )
library(recipes)
library("tseries")
library(tseries)
library(xtable)
library(groupdata2)
library(tseries)
# clear all environment variable
rm(list = ls())
# Read Dataset from csv file
x = read.csv("Sleep_Efficiency.csv")
# creating dummy variable for gender and smoking status
x$Smoking.status <- as.numeric(as.factor(x$Smoking.status))
x$Smoking.status <- ifelse(x$Smoking.status==2,1,0)
x$Gender <- ifelse(x$Gender=="Male",1,0)
# removing useless column
x <- x[,-1]
x <- x[,-3]
x <- x[,-3]
x <- x[,-7]
# omitting NA and creating x and y variables
x <- na.omit(x)
y <- x$Sleep.efficiency
# saving number of original columns
dim = ncol(x)
n = 500
set.seed(42)
train <- sample(dim(x)[1],floor(dim(x)[1]*0.75),replace = FALSE);
rand_model <- randomForest(x$Sleep.efficiency ~ . ,data = x, subset = train,
mtry = 5, importance = TRUE, replace = TRUE, ntree = 200)
plot(rand_model, main="Random forest model")
rand_fit <- predict(rand_model, newdata = x[-train,])
plot(rand_fit, x$Sleep.efficiency[-train])
abline(0,1)
MSE_rand = mean((x$Sleep.efficiency[-train] - rand_fit)^2)
MSE_rand
sqrt(MSE_rand)
#calcolo dell'R^2
D_tot = sum((x$Sleep.efficiency[-train] - mean(x$Sleep.efficiency[-train]))^2)
D_res = sum((x$Sleep.efficiency[-train] - rand_fit)^2)
r_2 = 1- D_res/D_tot
r_2
#funzione calcolo R^2
calcoloR_2 <- function(y, y_hat){
D_tot = sum((y - mean(y))^2)
D_res = sum((y - y_hat)^2)
return( 1- D_res/D_tot)
}
get_alpha_tree <- function(data,index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency ~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x,get_alpha_tree,R=2000) #attenzione 'x' minuscola in questo caso
res_predizioni_3[["t"]]
hist(res[["t"]][,1])
IC_up_predictions_3 <- numeric(nrow(x[-train,]))
IC_down_predictions_3 <- numeric(nrow(x[-train,]))
medie_pre_3 <- numeric(length(IC_up_predictions_3))
y_test_3 <- x[-train,4]
isDentro_3 <- numeric(ncol(res_predizioni_3[["t"]]))
for (k in 1:ncol(res_predizioni_3[["t"]])){
IC_up_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.975)
IC_down_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.025)
medie_pre_3[k] = mean(res_predizioni_3[["t"]][,k])
isDentro_3[k] <- ifelse(y_test_3[k] >= IC_down_predictions_3[k] && y_test_3[k] <= IC_up_predictions_3[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred_3 <- data.frame(rand_fit,  IC_down_predictions_3, y_test_3, IC_up_predictions_3,isDentro_3)
sum(isDentro_3)
IC_up_predictions <- numeric(nrow(x[-train,]))
IC_down_predictions <- numeric(nrow(x[-train,]))
medie_pre <- numeric(length(IC_up_predictions))
y_test <- x[-train,4]
isDentro <- numeric(ncol(res_predizioni[["t"]]))
for (k in 1:ncol(res_predizioni[["t"]])){
IC_up_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.975)
IC_down_predictions[k] <- quantile(res_predizioni[["t"]][,k], 0.025)
medie_pre[k] = mean(res_predizioni[["t"]][,k])
isDentro[k] <- ifelse(y_test[k] >= IC_down_predictions[k] && y_test[k] <= IC_up_predictions[k], 1, 0)
}
#pnormGC(0.975, region = 'below', mean = 0, std = 1, graph = TRUE)
z = qnorm(0.975, mean=0, sd=1)
IC_up_predictions_2 <- numeric(nrow(x[-train,]))
IC_down_predictions_2 <- numeric(nrow(x[-train,]))
isDentro_2 <- numeric(length(rand_fit))
for (k in 1:length(rand_fit)){
IC_up_predictions_2[k] <- rand_fit[k] + z*sqrt(MSE_rand)
IC_down_predictions_2[k] <- rand_fit[k] - z*sqrt(MSE_rand)
isDentro_2[k] <- ifelse(y_test[k] >= IC_down_predictions_2[k] && y_test[k] <= IC_up_predictions_2[k], 1, 0)
}
#media del valore IC up IC down
tabella_pred <- data.frame(medie_pre,  IC_down_predictions, y_test, IC_up_predictions,isDentro)
#media del valore IC up IC down
tabella_pred_2 <- data.frame(rand_fit,  IC_down_predictions_2, y_test, IC_up_predictions_2,isDentro_2)
View(tabella_pred_3)
get_alpha_tree <- function(data,index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency ~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
tree_cv <- cv.tree(temp_tree_model, FUN = prune.misclass)
temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x,get_alpha_tree,R=2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data,index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency ~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x,get_alpha_tree,R=2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data,index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency ~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
best = min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k = min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(tree_model, best = best)
temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x,get_alpha_tree,R=2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data,index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency ~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
best = min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k = min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best)
temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x,get_alpha_tree,R=2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best, k = k)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features])
###parte nuova
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best, k = k)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
###parte nuova
tree_cv <- cv.tree(temp_tree_model, rand = temp_features, FUN = prune.tree)
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, rand = temp_features, FUN = prune.tree)
best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best, k = k)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
res_predizioni_3[["t"]]
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, rand = temp_features, FUN = prune.tree)
best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best, k = k)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
?cv.tree
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree(temp_tree_model, newdata = data[,temp_features] ) )
best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best, k = k)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best, k = k)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_data <- data[, temp_features]
temp_tree_model <- tree(data$Sleep.efficiency~ . , data=temp_data, subset= temp_train, split = 'gini')
###parte nuova
tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model, best = best, k = k)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
#tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
#best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
#k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features])
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso
get_alpha_tree <- function(data, index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency~ . , data= data[,temp_features], subset= temp_train, split = 'gini')
###parte nuova
#tree_cv <- cv.tree(temp_tree_model, FUN = prune.tree)
#best <- min(tree_cv$size[tree_cv$dev == min(tree_cv$dev)])
#k <- min(tree_cv$k[tree_cv$dev == min(tree_cv$dev)]) #alpha in the book
prune <- prune.tree(temp_tree_model)
temp_fitt_value <- predict(prune, newdata = data[-train, temp_features], type='class')
######
#temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x, get_alpha_tree, R = 2000) #attenzione 'x' minuscola in questo caso

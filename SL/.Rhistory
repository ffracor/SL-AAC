p3<-barplot(table(x$Sleep.duration), main="" , xlab = "Sleep Duration [h]", ylab= "Frequency")
p8 <- barplot(table(x$Caffeine.consumption), main="" , xlab = expression(paste("Caffeine Consumption [", mu, "g/day]")), ylab= "Frequency")
p9<-barplot(table(x$Alcohol.consumption), main="" , xlab = expression(paste("Alcohol Consumption [oz/day]")), ylab= "Frequency")
p10<-barplot(table(x$Smoking.status), main="" , xlab = "Smoking Status", ylab= "Frequency")
p11<-barplot(table(x$Exercise.frequency), main="" , xlab = "Exercise Frequency", ylab= "Frequency")
par(mfrow = c(1,3))
p1<-hist(x$Age, main="" , xlab = "Age [years]", ylab= "Frequency")
p5<-hist(x$REM.sleep.percentage, main="" , xlab = "REM Sleep Percentage [%]", ylab= "Frequency")
p6<-hist(x$Deep.sleep.percentage, main="" , xlab = "Deep Sleep Percentage [%]", ylab= "Frequency")
par(mfrow = c(1,2))
p7<-barplot(table(x$Awakenings), main="" , xlab = "Awakenings", ylab= "Frequency")
p4<-hist(x$Sleep.efficiency, main="" , xlab = "Sleep Efficiency", ylab= "Frequency")
# saving number of original columns
dim = ncol(x)
n = 2000
train <- sample(dim(x)[1],floor(dim(x)[1]*0.75),replace = FALSE);
calcoloR_2 <- function(y, y_hat){
D_tot = sum((y - mean(y))^2)
D_res = sum((y - y_hat)^2)
return( 1- D_res/D_tot)
}
# STEPWISE
#inizializzo il vettore per il conteggio
col_name <- c("(Intercept)",colnames(x))
contatore_vect_SW <- setNames(numeric(length(col_name)), col_name)
dim = length(col_name)
# Define bootstrap function
get_alpha_SW <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
mdl <- lm(Sleep.efficiency ~ . , data = x[temp_train,])
step.model <- stepAIC(mdl, direction = "both",
trace = FALSE)
#parte per conteggio delle comparse
coeff_stimati <- names(step.model$coefficients)
i=0
for (i in 1:dim){
if(names(contatore_vect_SW[i]) %in% coeff_stimati){
contatore_vect_SW[i] <<- contatore_vect_SW[i] + 1
}
}
}
#Bootstrap per calcolare le volte in cui un regressore compare all'interno della stepwise
res_sw <- boot(x,get_alpha_SW,R = n, parallel = "multicore")
stepwise_significativi <- names(contatore_vect_SW[contatore_vect_SW > n/2])
stepwise_significativi <- stepwise_significativi[-1] #togliamo l'intercetta per poter usare il comando reformulate
stepwise_final_model <- lm(reformulate(stepwise_significativi, "Sleep.efficiency"), data=x)
summary(stepwise_final_model)
#Funzione bootrap per intervalli di confidenza sui coefficienti, MSE e R2
get_alpha <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
temp_mdl <- lm(reformulate(stepwise_significativi, "Sleep.efficiency"), data=x, subset = temp_train)
temp_fitt_value <- predict(temp_mdl, data[-temp_train,])
temp_test_MSE = mean((data$Sleep.efficiency[-temp_train] - temp_fitt_value)^2)
temp_r2 <- summary(temp_mdl)$r.squared
return (c(temp_test_MSE, temp_r2, temp_mdl$coefficients))
}
# Use boot() function to perform bootstrap simulations
res <- boot(x,get_alpha,R=n)
p <- res[["t"]]
Coefficients_stepwise_final <- res[["t"]][,3:(length(stepwise_significativi)+3)] #prendo da 3 in poi (8 coefficienti + intercetta e i primi 2 sono R2 e mse)
MSE_stepwise_final <- mean(res[["t"]][,1])
r2_SW <- mean(res[["t"]][,2])
mean(MSE_stepwise_final)
hist(MSE_stepwise_final, main="Stepwise MSE", sub="")
#creazione vettore per intervalli di confidenza
IC_up_SW <- setNames(numeric(length(stepwise_significativi)+3), c("MSE", "R2", "Intercept", stepwise_significativi))
IC_down_SW <- setNames(numeric(length(stepwise_significativi)+3), c("MSE", "R2", "Intercept", stepwise_significativi))
isSignificativo <- setNames(numeric(length(stepwise_significativi)+3), c("MSE", "R2", "Intercept", stepwise_significativi))
for (k in 1:ncol(res[["t"]])){
IC_up_SW[k] <- quantile(res[["t"]][,k], 0.975)
IC_down_SW[k] <- quantile(res[["t"]][,k], 0.025)
isSignificativo[k] <- ifelse(IC_up_SW[k]*IC_down_SW[k]<=0,0,1)
}
media_beta <- numeric(length(stepwise_significativi)+1) #aggiungo 1 perchÃ¨ rispetto a quelli del reformulate mi serve spazio per l'intercetta
Coefficients_stepwise_final
for (k in 1:(length(stepwise_significativi)+1)){
media_beta[k] <- mean(Coefficients_stepwise_final[,k]) #non calcolo media di mse e r2
}
#magari mettiamo anche quellinon significativi?!
tabella_stepwise <- data.frame(media_beta, IC_down_SW[-1:-2], IC_up_SW[-1:-2])
print_tab <- xtable(tabella_stepwise, digits=6)
print.xtable(print_tab)
#vettore delle comparse
(contatore_vect_SW[-1]/(n+1))*100 #di cui non vogliamo visualizzare l'intercetta [-1]
#LASSO REGRESSION
X <- model.matrix(Sleep.efficiency ~ . , data = x)
Y <- y
#inizializzazione per conteggio lasso
contatore_vect_LASSO <- setNames(numeric(length(col_name)), col_name)
cv_lasso <- cv.glmnet(X, Y, alpha = 1, nfolds = 10, lambda = NULL)
lasso_opt_lambda_s = cv_lasso$lambda.min
glm_model_lasso_s = glmnet(X[train,], Y[train],alpha = 1, lambda = lasso_opt_lambda_s)
plot(cv_lasso)
#Bootstrap su lasso
get_alpha_L <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
glm_model_lasso = glmnet(data[temp_train,], Y[temp_train],alpha = 1, lambda = lasso_opt_lambda_s)
temp_fitt_value <- predict(glm_model_lasso, s = lasso_opt_lambda_s, newx = data[-temp_train,])
lasso_test_MSE = mean((Y[-temp_train] - temp_fitt_value)^2)
temp_r2 <-calcoloR_2(Y[-temp_train], temp_fitt_value)
coeff_stimati <- names(glm_model_lasso$beta[, 1][glm_model_lasso$beta[, 1] != 0])
i=0
for (i in 1:dim){
if(names(contatore_vect_LASSO[i]) %in% coeff_stimati){
contatore_vect_LASSO[i] <<- contatore_vect_LASSO[i] + 1
}
}
return (c(lasso_test_MSE, temp_r2))
}
# Use boot() function to perform bootstrap simulations
res_lasso <- boot(X,get_alpha_L,R=n, parallel = "multicore")
MSE_lasso <- mean(res_lasso[["t"]][,1])
r2_lasso <- mean(res_lasso[["t"]][,2])
hist(MSE_lasso, main= "Lasso MSE")
mean(MSE_lasso)
#stampa delle frequezne di apparizione
100*contatore_vect_LASSO/(n+1)
lasso_significativi <- names(contatore_vect_LASSO[contatore_vect_LASSO > n/2])
lasso_significativi
lassoIsSignificativo <- ifelse((contatore_vect_LASSO > n/2), "Yes", "No")
tabella_lasso <- data.frame(glm_model_lasso_s$beta[,1])
xtable(tabella_lasso, digits=3)
cv_ridge <- cv.glmnet(X, Y, alpha = 0, nfolds = 10, lambda = NULL);
ridge_opt_lambda = cv_ridge$lambda.min;
get_alpha_ridge <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
glm_model_ridge = glmnet(data[temp_train,], Y[temp_train],alpha = 0, lambda = ridge_opt_lambda)
temp_fitt_value <- predict(glm_model_ridge, s = ridge_opt_lambda, newx = data[-temp_train,])
ridge_test_MSE = mean((Y[-temp_train] - temp_fitt_value)^2)
temp_r2 <-calcoloR_2(Y[-temp_train], temp_fitt_value)
return  (c(temp_r2, ridge_test_MSE))
}
# Use boot() function to perform bootstrap simulations
res_ridge <- boot(X,get_alpha_ridge,R=n, parallel = "multicore")
MSE_ridge <- mean(res_ridge[["t"]][,2])
r2_ridge <- mean(res_ridge[["t"]][,1])
hist(MSE_ridge, main="Ridge MSE")
mean(MSE_ridge)
plot(cv_ridge)
#BAGGING
bagg_model <- randomForest(Sleep.efficiency ~ . ,data = x, subset = train, mtry = ncol(x)-1, importance = TRUE, replace = TRUE, ntree = 200)
plot(bagg_model, main="Bagging model")
bagg_fit <- predict(bagg_model, newdata = x[-train,])
plot(bagg_fit, x$Sleep.efficiency[-train])
abline(0,1)
MSE_bagg <- mean((x$Sleep.efficiency[-train] - bagg_fit)^2)
r2_bagg <- calcoloR_2(x$Sleep.efficiency[-train], bagg_fit)
#RANDOM FOREST (guardare Cov.r per questa analisi sul ranodm forest)
dim = ncol(x)
n = 150
train <- sample(dim(x)[1],floor(dim(x)[1]*0.75),replace = FALSE);
rand_model <- randomForest(x$Sleep.efficiency ~ . ,data = x, subset = train,
mtry = 5, importance = TRUE, replace = TRUE, ntree = n, keep.forest = TRUE)
plot(rand_model, main="Random forest model")
rand_fit <- predict(rand_model, newdata = x[-train,])
plot(rand_fit, x$Sleep.efficiency[-train])
abline(0,1)
MSE_rand_RF = mean((x$Sleep.efficiency[-train] - rand_fit)^2)
r2_rand_RF <- calcoloR_2(x$Sleep.efficiency[-train], rand_fit)
get_alpha_tree <- function(data,index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency ~ . , data= data[,temp_features], subset= temp_train, split='gini')
temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
# temp_r2 <- calcoloR_2(data$Sleep.efficiency[-train], temp_fitt_value)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x,get_alpha_tree,R=n) #attenzione 'x' minuscola in questo caso
IC_up_predictions_3 <- numeric(nrow(x[-train,]))
IC_down_predictions_3 <- numeric(nrow(x[-train,]))
medie_pre_3 <- numeric(length(IC_up_predictions_3))
y_test_3 <- x[-train,4]
isDentro_3 <- numeric(ncol(res_predizioni_3[["t"]]))
for (k in 1:ncol(res_predizioni_3[["t"]])){
IC_up_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.975)
IC_down_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.025)
medie_pre_3[k] = mean(res_predizioni_3[["t"]][,k])
isDentro_3[k] <- ifelse(y_test_3[k] >= IC_down_predictions_3[k] && y_test_3[k] <= IC_up_predictions_3[k], 1, 0)
}
MSE_naive_RF = mean((x$Sleep.efficiency[-train] - medie_pre_3)^2)
sqrt(MSE_naive_RF)
r2_naive_RF <- calcoloR_2(x$Sleep.efficiency[-train], medie_pre_3)
#media del valore IC up IC down
tabella_pred_3 <- data.frame(medie_pre_3,  IC_down_predictions_3, y_test_3, IC_up_predictions_3,isDentro_3)
sum(isDentro_3)
#inizializzo il vettore per il conteggio
col_name <- c("(Intercept)",colnames(x))
contatore_vect_POISS <- setNames(numeric(length(col_name)), col_name)
dim = length(col_name)
# Define bootstrap function
get_alpha_POISS <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
pois_mdl <- glm(Awakenings ~ . , data = x[temp_train,] , family = poisson)
# print(pois_mdl$coefficients)
#step_pois <- stepAIC(pois_mdl, direction = "both",
#                     trace = FALSE)
#parte per conteggio delle comparse
coeff_stimati <- names(pois_mdl$coefficients)
i=0
for (i in 1:dim){
if(names(contatore_vect_POISS[i]) %in% coeff_stimati){
contatore_vect_POISS[i] <<- contatore_vect_POISS[i] + 1
}
}
return(pois_mdl$coefficients)
}
n = 2000
# Use boot() function to perform bootstrap simulations
coefficients_sw_poiss <- boot(x,get_alpha_POISS,R = n, parallel = "multicore")
#calcolo degli intervalli di confidenza
IC_up_predictions_poiss <- numeric(ncol(x))
IC_down_predictions_poiss <- numeric(ncol(x))
medie_coeff_poiss <- numeric(length(IC_up_predictions_poiss))
col_name <- names(coefficients_sw_poiss[["t0"]])
medie_coeff_poiss <- setNames(numeric(length(col_name)), col_name)
isSignificativo_poiss<- setNames(numeric(length(col_name)), col_name)
for (k in 1:ncol(coefficients_sw_poiss[["t"]])){
IC_up_predictions_poiss[k] <- quantile(coefficients_sw_poiss[["t"]][,k], 0.995)
IC_down_predictions_poiss[k] <- quantile(coefficients_sw_poiss[["t"]][,k], 0.005)
medie_coeff_poiss[k] <- mean(coefficients_sw_poiss[["t"]][,k])
isSignificativo_poiss[k] <- ifelse(IC_down_predictions_poiss[k]*IC_up_predictions_poiss[k] >=0, 1, 0)
}
tabella_pred <- data.frame(medie_coeff_poiss,  IC_down_predictions_poiss, IC_up_predictions_poiss, isSignificativo_poiss)
stepwise_significativi_poiss <- names(isSignificativo_poiss[isSignificativo_poiss == 1])
#stepwise_significativi_poiss <- stepwise_significativi_poiss[-1]
stepwise_significativi_poiss <- stepwise_significativi_poiss[-1]
#reformulate ha problemi con l'intercetta
stepwise_final_model_poiss <- glm(reformulate(stepwise_significativi_poiss, "Awakenings"), data=x, family = 'poisson')
summary(stepwise_final_model_poiss)
pred <- predict(stepwise_final_model_poiss,type="response")
plot(x$Awakenings,pred)
# clear all environment variable
rm(list = ls())
set.seed(42)
# Read Dataset from csv file
x = read.csv("Sleep_Efficiency.csv")
# creating dummy variable for gender and smoking status
x$Smoking.status <- as.numeric(as.factor(x$Smoking.status))
x$Smoking.status <- ifelse(x$Smoking.status==2,1,0)
x$Gender <- ifelse(x$Gender=="Male",1,0)
# removing useless column
x <- x[,-1]
x <- x[,-3]
x <- x[,-3]
x <- x[,-7]
# omitting NA and creating x and y variables
x <- na.omit(x)
y <- x$Sleep.efficiency
corr_matrix <- cor(x)
corrplot(corr_matrix, type="upper", order="hclust")
par(mfrow = c(2,3))
p2<-barplot(table(x$Gender), main="" , xlab = "Gender", ylab= "Frequency")
p3<-barplot(table(x$Sleep.duration), main="" , xlab = "Sleep Duration [h]", ylab= "Frequency")
p8 <- barplot(table(x$Caffeine.consumption), main="" , xlab = expression(paste("Caffeine Consumption [", mu, "g/day]")), ylab= "Frequency")
p9<-barplot(table(x$Alcohol.consumption), main="" , xlab = expression(paste("Alcohol Consumption [oz/day]")), ylab= "Frequency")
p10<-barplot(table(x$Smoking.status), main="" , xlab = "Smoking Status", ylab= "Frequency")
p11<-barplot(table(x$Exercise.frequency), main="" , xlab = "Exercise Frequency", ylab= "Frequency")
par(mfrow = c(1,3))
p1<-hist(x$Age, main="" , xlab = "Age [years]", ylab= "Frequency")
p5<-hist(x$REM.sleep.percentage, main="" , xlab = "REM Sleep Percentage [%]", ylab= "Frequency")
p6<-hist(x$Deep.sleep.percentage, main="" , xlab = "Deep Sleep Percentage [%]", ylab= "Frequency")
par(mfrow = c(1,2))
p7<-barplot(table(x$Awakenings), main="" , xlab = "Awakenings", ylab= "Frequency")
p4<-hist(x$Sleep.efficiency, main="" , xlab = "Sleep Efficiency", ylab= "Frequency")
# saving number of original columns
dim = ncol(x)
n = 2000
train <- sample(dim(x)[1],floor(dim(x)[1]*0.75),replace = FALSE);
calcoloR_2 <- function(y, y_hat){
D_tot = sum((y - mean(y))^2)
D_res = sum((y - y_hat)^2)
return( 1- D_res/D_tot)
}
# STEPWISE
#inizializzo il vettore per il conteggio
col_name <- c("(Intercept)",colnames(x))
contatore_vect_SW <- setNames(numeric(length(col_name)), col_name)
dim = length(col_name)
# Define bootstrap function
get_alpha_SW <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
mdl <- lm(Sleep.efficiency ~ . , data = x[temp_train,])
step.model <- stepAIC(mdl, direction = "both",
trace = FALSE)
#parte per conteggio delle comparse
coeff_stimati <- names(step.model$coefficients)
i=0
for (i in 1:dim){
if(names(contatore_vect_SW[i]) %in% coeff_stimati){
contatore_vect_SW[i] <<- contatore_vect_SW[i] + 1
}
}
}
#Bootstrap per calcolare le volte in cui un regressore compare all'interno della stepwise
res_sw <- boot(x,get_alpha_SW,R = n, parallel = "multicore")
stepwise_significativi <- names(contatore_vect_SW[contatore_vect_SW > n/2])
stepwise_significativi <- stepwise_significativi[-1] #togliamo l'intercetta per poter usare il comando reformulate
stepwise_final_model <- lm(reformulate(stepwise_significativi, "Sleep.efficiency"), data=x)
summary(stepwise_final_model)
#Funzione bootrap per intervalli di confidenza sui coefficienti, MSE e R2
get_alpha <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
temp_mdl <- lm(reformulate(stepwise_significativi, "Sleep.efficiency"), data=x, subset = temp_train)
temp_fitt_value <- predict(temp_mdl, data[-temp_train,])
temp_test_MSE = mean((data$Sleep.efficiency[-temp_train] - temp_fitt_value)^2)
temp_r2 <- summary(temp_mdl)$r.squared
return (c(temp_test_MSE, temp_r2, temp_mdl$coefficients))
}
# Use boot() function to perform bootstrap simulations
res <- boot(x,get_alpha,R=n)
p <- res[["t"]]
Coefficients_stepwise_final <- res[["t"]][,3:(length(stepwise_significativi)+3)] #prendo da 3 in poi (8 coefficienti + intercetta e i primi 2 sono R2 e mse)
MSE_stepwise_final <- mean(res[["t"]][,1])
r2_SW <- mean(res[["t"]][,2])
mean(MSE_stepwise_final)
hist(MSE_stepwise_final, main="Stepwise MSE", sub="")
#creazione vettore per intervalli di confidenza
IC_up_SW <- setNames(numeric(length(stepwise_significativi)+3), c("MSE", "R2", "Intercept", stepwise_significativi))
IC_down_SW <- setNames(numeric(length(stepwise_significativi)+3), c("MSE", "R2", "Intercept", stepwise_significativi))
isSignificativo <- setNames(numeric(length(stepwise_significativi)+3), c("MSE", "R2", "Intercept", stepwise_significativi))
for (k in 1:ncol(res[["t"]])){
IC_up_SW[k] <- quantile(res[["t"]][,k], 0.975)
IC_down_SW[k] <- quantile(res[["t"]][,k], 0.025)
isSignificativo[k] <- ifelse(IC_up_SW[k]*IC_down_SW[k]<=0,0,1)
}
media_beta <- numeric(length(stepwise_significativi)+1) #aggiungo 1 perchÃ¨ rispetto a quelli del reformulate mi serve spazio per l'intercetta
Coefficients_stepwise_final
for (k in 1:(length(stepwise_significativi)+1)){
media_beta[k] <- mean(Coefficients_stepwise_final[,k]) #non calcolo media di mse e r2
}
#magari mettiamo anche quellinon significativi?!
tabella_stepwise <- data.frame(media_beta, IC_down_SW[-1:-2], IC_up_SW[-1:-2])
print_tab <- xtable(tabella_stepwise, digits=6)
print.xtable(print_tab)
#vettore delle comparse
(contatore_vect_SW[-1]/(n+1))*100 #di cui non vogliamo visualizzare l'intercetta [-1]
#LASSO REGRESSION
X <- model.matrix(Sleep.efficiency ~ . , data = x)
Y <- y
#inizializzazione per conteggio lasso
contatore_vect_LASSO <- setNames(numeric(length(col_name)), col_name)
cv_lasso <- cv.glmnet(X, Y, alpha = 1, nfolds = 10, lambda = NULL)
lasso_opt_lambda_s = cv_lasso$lambda.min
glm_model_lasso_s = glmnet(X[train,], Y[train],alpha = 1, lambda = lasso_opt_lambda_s)
plot(cv_lasso)
#Bootstrap su lasso
get_alpha_L <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
glm_model_lasso = glmnet(data[temp_train,], Y[temp_train],alpha = 1, lambda = lasso_opt_lambda_s)
temp_fitt_value <- predict(glm_model_lasso, s = lasso_opt_lambda_s, newx = data[-temp_train,])
lasso_test_MSE = mean((Y[-temp_train] - temp_fitt_value)^2)
temp_r2 <-calcoloR_2(Y[-temp_train], temp_fitt_value)
coeff_stimati <- names(glm_model_lasso$beta[, 1][glm_model_lasso$beta[, 1] != 0])
i=0
for (i in 1:dim){
if(names(contatore_vect_LASSO[i]) %in% coeff_stimati){
contatore_vect_LASSO[i] <<- contatore_vect_LASSO[i] + 1
}
}
return (c(lasso_test_MSE, temp_r2))
}
# Use boot() function to perform bootstrap simulations
res_lasso <- boot(X,get_alpha_L,R=n, parallel = "multicore")
MSE_lasso <- mean(res_lasso[["t"]][,1])
r2_lasso <- mean(res_lasso[["t"]][,2])
hist(MSE_lasso, main= "Lasso MSE")
mean(MSE_lasso)
#stampa delle frequezne di apparizione
100*contatore_vect_LASSO/(n+1)
lasso_significativi <- names(contatore_vect_LASSO[contatore_vect_LASSO > n/2])
lasso_significativi
lassoIsSignificativo <- ifelse((contatore_vect_LASSO > n/2), "Yes", "No")
tabella_lasso <- data.frame(glm_model_lasso_s$beta[,1])
xtable(tabella_lasso, digits=3)
cv_ridge <- cv.glmnet(X, Y, alpha = 0, nfolds = 10, lambda = NULL);
ridge_opt_lambda = cv_ridge$lambda.min;
get_alpha_ridge <- function(data,index){
temp_train <- sample(nrow(data), floor(nrow(data) * 0.75), replace = TRUE)
glm_model_ridge = glmnet(data[temp_train,], Y[temp_train],alpha = 0, lambda = ridge_opt_lambda)
temp_fitt_value <- predict(glm_model_ridge, s = ridge_opt_lambda, newx = data[-temp_train,])
ridge_test_MSE = mean((Y[-temp_train] - temp_fitt_value)^2)
temp_r2 <-calcoloR_2(Y[-temp_train], temp_fitt_value)
return  (c(temp_r2, ridge_test_MSE))
}
# Use boot() function to perform bootstrap simulations
res_ridge <- boot(X,get_alpha_ridge,R=n, parallel = "multicore")
MSE_ridge <- mean(res_ridge[["t"]][,2])
r2_ridge <- mean(res_ridge[["t"]][,1])
hist(MSE_ridge, main="Ridge MSE")
mean(MSE_ridge)
plot(cv_ridge)
#BAGGING
bagg_model <- randomForest(Sleep.efficiency ~ . ,data = x, subset = train, mtry = ncol(x)-1, importance = TRUE, replace = TRUE, ntree = 200)
plot(bagg_model, main="Bagging model")
bagg_fit <- predict(bagg_model, newdata = x[-train,])
plot(bagg_fit, x$Sleep.efficiency[-train])
abline(0,1)
MSE_bagg <- mean((x$Sleep.efficiency[-train] - bagg_fit)^2)
r2_bagg <- calcoloR_2(x$Sleep.efficiency[-train], bagg_fit)
#RANDOM FOREST (guardare Cov.r per questa analisi sul ranodm forest)
dim = ncol(x)
n = 150
train <- sample(dim(x)[1],floor(dim(x)[1]*0.75),replace = FALSE);
rand_model <- randomForest(x$Sleep.efficiency ~ . ,data = x, subset = train,
mtry = 5, importance = TRUE, replace = TRUE, ntree = n, keep.forest = TRUE)
plot(rand_model, main="Random forest model")
rand_fit <- predict(rand_model, newdata = x[-train,])
plot(rand_fit, x$Sleep.efficiency[-train])
abline(0,1)
MSE_rand_RF = mean((x$Sleep.efficiency[-train] - rand_fit)^2)
r2_rand_RF <- calcoloR_2(x$Sleep.efficiency[-train], rand_fit)
get_alpha_tree <- function(data,index){
temp_train <- sample(train, length(train), replace = TRUE)
temp_features <- sample(10, 5, replace = FALSE)
temp_features[temp_features==4] <- 11
temp_tree_model <- tree(data$Sleep.efficiency ~ . , data= data[,temp_features], subset= temp_train, split='gini')
temp_fitt_value <- predict(temp_tree_model, newdata = data[-train, temp_features])
#temp_test_MSE = mean((data$Sleep.efficiency[-train] - temp_fitt_value)^2)
# temp_r2 <- calcoloR_2(data$Sleep.efficiency[-train], temp_fitt_value)
return (temp_fitt_value)
}
res_predizioni_3 <- boot(x,get_alpha_tree,R=n) #attenzione 'x' minuscola in questo caso
IC_up_predictions_3 <- numeric(nrow(x[-train,]))
IC_down_predictions_3 <- numeric(nrow(x[-train,]))
medie_pre_3 <- numeric(length(IC_up_predictions_3))
y_test_3 <- x[-train,4]
isDentro_3 <- numeric(ncol(res_predizioni_3[["t"]]))
for (k in 1:ncol(res_predizioni_3[["t"]])){
IC_up_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.975)
IC_down_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.025)
medie_pre_3[k] = mean(res_predizioni_3[["t"]][,k])
isDentro_3[k] <- ifelse(y_test_3[k] >= IC_down_predictions_3[k] && y_test_3[k] <= IC_up_predictions_3[k], 1, 0)
}
MSE_naive_RF = mean((x$Sleep.efficiency[-train] - medie_pre_3)^2)
sqrt(MSE_naive_RF)
r2_naive_RF <- calcoloR_2(x$Sleep.efficiency[-train], medie_pre_3)
#media del valore IC up IC down
tabella_pred_3 <- data.frame(medie_pre_3,  IC_down_predictions_3, y_test_3, IC_up_predictions_3,isDentro_3)
sum(isDentro_3)
par(mfrow = c(1,2))
plot(cv_ridge)
par(mfrow = c(1,2))
plot(bagg_model, main="Bagging model")
plot(rand_model, main="Random forest model")
IC_up_predictions_3 <- numeric(nrow(x[-train,]))
IC_down_predictions_3 <- numeric(nrow(x[-train,]))
medie_pre_3 <- numeric(length(IC_up_predictions_3))
y_test_3 <- x[-train,4]
isDentro_3 <- numeric(ncol(res_predizioni_3[["t"]]))
for (k in 1:ncol(res_predizioni_3[["t"]])){
IC_up_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.95)
IC_down_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.05)
medie_pre_3[k] = mean(res_predizioni_3[["t"]][,k])
isDentro_3[k] <- ifelse(y_test_3[k] >= IC_down_predictions_3[k] && y_test_3[k] <= IC_up_predictions_3[k], 1, 0)
}
MSE_naive_RF = mean((x$Sleep.efficiency[-train] - medie_pre_3)^2)
sqrt(MSE_naive_RF)
r2_naive_RF <- calcoloR_2(x$Sleep.efficiency[-train], medie_pre_3)
#media del valore IC up IC down
tabella_pred_3 <- data.frame(medie_pre_3,  IC_down_predictions_3, y_test_3, IC_up_predictions_3,isDentro_3)
sum(isDentro_3)
View(tabella_pred_3)
View(tabella_pred_3)
IC_up_predictions_3 <- numeric(nrow(x[-train,]))
IC_down_predictions_3 <- numeric(nrow(x[-train,]))
medie_pre_3 <- numeric(length(IC_up_predictions_3))
y_test_3 <- x[-train,4]
isDentro_3 <- numeric(ncol(res_predizioni_3[["t"]]))
for (k in 1:ncol(res_predizioni_3[["t"]])){
IC_up_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.975)
IC_down_predictions_3[k] <- quantile(res_predizioni_3[["t"]][,k], 0.025)
medie_pre_3[k] = mean(res_predizioni_3[["t"]][,k])
isDentro_3[k] <- ifelse(y_test_3[k] >= IC_down_predictions_3[k] && y_test_3[k] <= IC_up_predictions_3[k], 1, 0)
}
MSE_naive_RF = mean((x$Sleep.efficiency[-train] - medie_pre_3)^2)
sqrt(MSE_naive_RF)
r2_naive_RF <- calcoloR_2(x$Sleep.efficiency[-train], medie_pre_3)
#media del valore IC up IC down
tabella_pred_3 <- data.frame(medie_pre_3,  IC_down_predictions_3, y_test_3, IC_up_predictions_3,isDentro_3)
sum(isDentro_3)
x[-train,4]
#media del valore IC up IC down
tabella_pred_3 <- data.frame(medie_pre_3,  IC_down_predictions_3, y_test_3, IC_up_predictions_3,isDentro_3)
xtable(tabell_pred_3, digits = 3)
library(tidyverse)
library(caret)
library(leaps)
library("MASS")
library("glmnet")
library ( ISLR2 )
library ( boot )
library(tree)
library ( randomForest )
library ( gbm )
library(recipes)
library("tseries")
library(tseries)
library(xtable)
library(groupdata2)
library(tseries)
library(corrplot)
library(gridExtra)
library(ggplot2)
xtable(tabell_pred_3, digits = 3)
#media del valore IC up IC down
tabella_pred_3 <- data.frame(medie_pre_3,  IC_down_predictions_3, y_test_3, IC_up_predictions_3,isDentro_3)
xtable(tabell_pred_3, digits = 3)
xtable(tabella_pred_3, digits = 3)
xtable(tabella_pred_3, digits = c(3,3,3,3,0))
xtable(tabella_pred_3, digits = c(0, 3,3,3,3,0))
